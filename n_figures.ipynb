{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in /root/miniconda3/lib/python3.9/site-packages (22.3.5)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.9/site-packages (from pycountry) (52.0.0.post20210125)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: basemap in /root/miniconda3/lib/python3.9/site-packages (1.3.6)\n",
      "Requirement already satisfied: pyshp<2.4,>=1.2 in /root/miniconda3/lib/python3.9/site-packages (from basemap) (2.3.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /root/miniconda3/lib/python3.9/site-packages (from basemap) (1.23.4)\n",
      "Requirement already satisfied: basemap-data<1.4,>=1.3.2 in /root/miniconda3/lib/python3.9/site-packages (from basemap) (1.3.2)\n",
      "Requirement already satisfied: pyproj<3.5.0,>=1.9.3 in /root/miniconda3/lib/python3.9/site-packages (from basemap) (3.4.0)\n",
      "Requirement already satisfied: matplotlib<3.7,>=1.5 in /root/miniconda3/lib/python3.9/site-packages (from basemap) (3.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib<3.7,>=1.5->basemap) (8.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib<3.7,>=1.5->basemap) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib<3.7,>=1.5->basemap) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib<3.7,>=1.5->basemap) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib<3.7,>=1.5->basemap) (1.3.1)\n",
      "Requirement already satisfied: six in /root/miniconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib<3.7,>=1.5->basemap) (1.16.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.9/site-packages (from pyproj<3.5.0,>=1.9.3->basemap) (2021.10.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry\n",
    "!pip install basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import lang2vec.lang2vec as l2v\n",
    "import importlib.resources\n",
    "from lang2vec import data as lang2vec_data\n",
    "import umap\n",
    "from mpl_toolkits.basemap import Basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `available_uriel_languages` from lang2vec is bugged so we need to extract languages manually\n",
    "dt = np.load(importlib.resources.open_binary(lang2vec_data, 'feature_predictions.npz'))\n",
    "uriel_languages = sorted(dt['langs'])\n",
    "\n",
    "uriel_features = l2v.get_features(\n",
    "    languages=uriel_languages,\n",
    "    feature_set_inp='syntax_knn+phonology_knn+inventory_knn',\n",
    "    header=True,\n",
    ")\n",
    "\n",
    "# CODE is a special value for feature names\n",
    "uriel_codes = uriel_features['CODE']\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [uriel_features[l] for l in uriel_languages],\n",
    "    index=uriel_languages,\n",
    "    columns=uriel_codes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206/3747773459.py:7: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  umap_object.fit(np.vstack(df[uriel_codes].itertuples(index=False, name=None)))\n"
     ]
    }
   ],
   "source": [
    "umap_object = umap.UMAP(\n",
    "    n_neighbors=200,\n",
    "    metric='cosine',\n",
    "    min_dist=0.5,\n",
    "    random_state=1,\n",
    ")\n",
    "umap_object.fit(np.vstack(df[uriel_codes].itertuples(index=False, name=None)))\n",
    "\n",
    "df['uriel_x'] = umap_object.embedding_[:,0]\n",
    "df['uriel_y'] = umap_object.embedding_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_iso(iso):\n",
    "    if len(iso) == 3:\n",
    "        return iso\n",
    "    isos = iso.split(', ')\n",
    "    for iso in isos:\n",
    "        if iso in uriel_languages:\n",
    "            return iso    \n",
    "\n",
    "# WALS files downloaded from https://github.com/cldf-datasets/wals/releases\n",
    "# Files can be found in `raw` folder\n",
    "lan_csv = pd.read_csv('language.csv').set_index('pk')        # Contains geographical coordinates\n",
    "wal_csv = pd.read_csv('walslanguage.csv').set_index('pk')    # Contains ISO codes\n",
    "wsl_df = lan_csv.join(wal_csv)\n",
    "\n",
    "# Normalize ISO codes, some are null, some have multiple variants\n",
    "wsl_df = wsl_df[wsl_df.iso_codes.notna()]\n",
    "wsl_df['iso_codes'] = wsl_df['iso_codes'].apply(normalize_iso)\n",
    "\n",
    "wsl_df = wsl_df[['iso_codes', 'latitude', 'longitude']].set_index('iso_codes')\n",
    "wsl_df = wsl_df[~wsl_df.index.duplicated()] \n",
    "# Multiple records can share one ISO code (e.g. Zulu, Zulu (northern), Zulu (southerns)) and they can even have different primary key\n",
    "# in `languages.csv` and different geographical coordinates. Here we simply select the first record. This might not be an optimal\n",
    "# solution, but it is only a handful of languages and I believe that the coordinates will still roughly match.\n",
    "\n",
    "df = df.join(wsl_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = l2v.get_features(\n",
    "    languages=uriel_languages,\n",
    "    feature_set_inp='fam',\n",
    "    header=True,\n",
    ")\n",
    "families_codes = families['CODE']\n",
    "fam_df = pd.DataFrame(\n",
    "    [families[l] for l in uriel_languages],\n",
    "    index=uriel_languages,\n",
    "    columns=families['CODE'],\n",
    ")\n",
    "\n",
    "df = df.join(fam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['family_str'] = [\n",
    "    ' '.join(f[2:] for i, f in zip(row, families_codes) if i)\n",
    "    for row in fam_df.itertuples(index=False, name=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "pycountry.languages._load()\n",
    "\n",
    "df['name'] = [\n",
    "    pycountry.languages.get(alpha_3=l).name if l in pycountry.languages.indices['alpha_3'] else None\n",
    "    for l in uriel_languages  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_SVO</th>\n",
       "      <th>S_SOV</th>\n",
       "      <th>S_VSO</th>\n",
       "      <th>S_VOS</th>\n",
       "      <th>S_OVS</th>\n",
       "      <th>S_OSV</th>\n",
       "      <th>S_SUBJECT_BEFORE_VERB</th>\n",
       "      <th>S_SUBJECT_AFTER_VERB</th>\n",
       "      <th>S_OBJECT_AFTER_VERB</th>\n",
       "      <th>S_OBJECT_BEFORE_VERB</th>\n",
       "      <th>...</th>\n",
       "      <th>F_Berawan</th>\n",
       "      <th>F_Central-East_Berawan</th>\n",
       "      <th>F_Iwaidjan_Proper_(Unattested)</th>\n",
       "      <th>F_West_Zapotec</th>\n",
       "      <th>F_West-Central_West_Zapotec</th>\n",
       "      <th>F_Coatec</th>\n",
       "      <th>F_Coatlan-Loxicha_Zapotec</th>\n",
       "      <th>F_Yongnan-Yongbei</th>\n",
       "      <th>family_str</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlantic-Congo Volta-Congo Benue-Congo Akpes-E...</td>\n",
       "      <td>Ghotuo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aab</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlantic-Congo Volta-Congo Benue-Congo Benue-C...</td>\n",
       "      <td>Alumu-Tesu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Suki-Gogodala Gogodalic</td>\n",
       "      <td>Ari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aad</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepik</td>\n",
       "      <td>Amal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aae</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indo-European Albanian Albanian-Tosk</td>\n",
       "      <td>Arbëreshë Albanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyj</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic No...</td>\n",
       "      <td>Youjiang Zhuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyn</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic Yo...</td>\n",
       "      <td>Yongnan Zhuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sino-Tibetan Kuki-Chin-Naga Kuki-Chin Maraic N...</td>\n",
       "      <td>Zyphe Chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zza</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indo-European Indo-Iranian Iranian Western_Ira...</td>\n",
       "      <td>Zaza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzj</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic</td>\n",
       "      <td>Zuojiang Zhuang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7970 rows × 4013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S_SVO  S_SOV  S_VSO  S_VOS  S_OVS  S_OSV  S_SUBJECT_BEFORE_VERB  \\\n",
       "aaa    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "aab    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "aac    0.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "aad    0.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "aae    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "..     ...    ...    ...    ...    ...    ...                    ...   \n",
       "zyj    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "zyn    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "zyp    0.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "zza    0.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "zzj    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "\n",
       "     S_SUBJECT_AFTER_VERB  S_OBJECT_AFTER_VERB  S_OBJECT_BEFORE_VERB  ...  \\\n",
       "aaa                   0.0                  1.0                   0.0  ...   \n",
       "aab                   0.0                  1.0                   0.0  ...   \n",
       "aac                   0.0                  0.0                   1.0  ...   \n",
       "aad                   0.0                  0.0                   1.0  ...   \n",
       "aae                   0.0                  1.0                   0.0  ...   \n",
       "..                    ...                  ...                   ...  ...   \n",
       "zyj                   0.0                  1.0                   0.0  ...   \n",
       "zyn                   0.0                  1.0                   0.0  ...   \n",
       "zyp                   0.0                  0.0                   1.0  ...   \n",
       "zza                   0.0                  0.0                   1.0  ...   \n",
       "zzj                   0.0                  1.0                   0.0  ...   \n",
       "\n",
       "     F_Berawan  F_Central-East_Berawan  F_Iwaidjan_Proper_(Unattested)  \\\n",
       "aaa        0.0                     0.0                             0.0   \n",
       "aab        0.0                     0.0                             0.0   \n",
       "aac        0.0                     0.0                             0.0   \n",
       "aad        0.0                     0.0                             0.0   \n",
       "aae        0.0                     0.0                             0.0   \n",
       "..         ...                     ...                             ...   \n",
       "zyj        0.0                     0.0                             0.0   \n",
       "zyn        0.0                     0.0                             0.0   \n",
       "zyp        0.0                     0.0                             0.0   \n",
       "zza        0.0                     0.0                             0.0   \n",
       "zzj        0.0                     0.0                             0.0   \n",
       "\n",
       "     F_West_Zapotec  F_West-Central_West_Zapotec  F_Coatec  \\\n",
       "aaa             0.0                          0.0       0.0   \n",
       "aab             0.0                          0.0       0.0   \n",
       "aac             0.0                          0.0       0.0   \n",
       "aad             0.0                          0.0       0.0   \n",
       "aae             0.0                          0.0       0.0   \n",
       "..              ...                          ...       ...   \n",
       "zyj             0.0                          0.0       0.0   \n",
       "zyn             0.0                          0.0       0.0   \n",
       "zyp             0.0                          0.0       0.0   \n",
       "zza             0.0                          0.0       0.0   \n",
       "zzj             0.0                          0.0       0.0   \n",
       "\n",
       "     F_Coatlan-Loxicha_Zapotec  F_Yongnan-Yongbei  \\\n",
       "aaa                        0.0                0.0   \n",
       "aab                        0.0                0.0   \n",
       "aac                        0.0                0.0   \n",
       "aad                        0.0                0.0   \n",
       "aae                        0.0                0.0   \n",
       "..                         ...                ...   \n",
       "zyj                        0.0                0.0   \n",
       "zyn                        0.0                1.0   \n",
       "zyp                        0.0                0.0   \n",
       "zza                        0.0                0.0   \n",
       "zzj                        0.0                0.0   \n",
       "\n",
       "                                            family_str                name  \n",
       "aaa  Atlantic-Congo Volta-Congo Benue-Congo Akpes-E...              Ghotuo  \n",
       "aab  Atlantic-Congo Volta-Congo Benue-Congo Benue-C...          Alumu-Tesu  \n",
       "aac                            Suki-Gogodala Gogodalic                 Ari  \n",
       "aad                                              Sepik                Amal  \n",
       "aae               Indo-European Albanian Albanian-Tosk  Arbëreshë Albanian  \n",
       "..                                                 ...                 ...  \n",
       "zyj  Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic No...     Youjiang Zhuang  \n",
       "zyn  Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic Yo...      Yongnan Zhuang  \n",
       "zyp  Sino-Tibetan Kuki-Chin-Naga Kuki-Chin Maraic N...          Zyphe Chin  \n",
       "zza  Indo-European Indo-Iranian Iranian Western_Ira...                Zaza  \n",
       "zzj        Tai-Kadai Kam-Tai Be-Tai Daic Northern_Daic     Zuojiang Zhuang  \n",
       "\n",
       "[7970 rows x 4013 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# df.loc['slk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962d74f0476d404ea6e0c43d37451b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def visualize(\n",
    "    backend,\n",
    "    features,\n",
    "    color_families=False,\n",
    "    legend_families=False,\n",
    "    alpha=1,\n",
    "    zoom=None,  # left right bottom up\n",
    "    evaluation=None,\n",
    "):\n",
    "    if color_families == True:\n",
    "        color_families = [\n",
    "            'Atlantic-Congo',\n",
    "            'Austronesian',\n",
    "            'Indo-European',\n",
    "            'Slavic',\n",
    "            'Germanic',\n",
    "            'Italic',\n",
    "            'Afro-Asiatic',\n",
    "            'Semitic',\n",
    "            'Sino-Tibetan',\n",
    "            'Nuclear_Trans_New_Guinea',\n",
    "            'Pama-Nyungan',\n",
    "            'Otomanguean',\n",
    "            'Austroasiatic',\n",
    "            'Dravidian',\n",
    "            'Turkic',\n",
    "            'Uralic',\n",
    "        ]\n",
    "    \n",
    "    if color_families:\n",
    "        color_families = ['F_' + family for family in color_families]\n",
    "    \n",
    "    if backend == 'matplotlib':\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "        \n",
    "        if features == 'uriel':\n",
    "    \n",
    "            if color_families:\n",
    "                other = df[~df[color_families].any(axis=1)]\n",
    "                plt.scatter(other.uriel_x, other.uriel_y, 3, c='gray', marker='o', label='Other' if legend_families else None, alpha=alpha)\n",
    "                for family in color_families:\n",
    "                    family_df = df[df[family] == 1]\n",
    "                    plt.scatter(family_df.uriel_x, family_df.uriel_y, 10, marker='o', label=family if legend_families else None, alpha=alpha)\n",
    "                    # TODO: fix colors\n",
    "                    # TODO: select each language only once, e.g. Indo-European vs Slavic\n",
    "\n",
    "            else:\n",
    "                plt.scatter(df.uriel_x, df.uriel_y, 3, marker='o', c='gray', alpha=alpha)\n",
    "                \n",
    "            if zoom is not None:\n",
    "                plt.xlim(zoom[0], zoom[1])\n",
    "                plt.ylim(zoom[2], zoom[3])\n",
    "                \n",
    "            if evaluation is not None:\n",
    "                subset_df = df.loc[evaluation.languages]\n",
    "                plt.scatter(subset_df['uriel_x'], subset_df['uriel_y'], s=evaluation.sizes, c=evaluation.colors)\n",
    "                \n",
    "                if evaluation.legend:\n",
    "                    for label, color, size in zip(evaluation.legend['labels'], evaluation.legend['colors'], evaluation.legend['sizes']):\n",
    "                        plt.scatter(None, None, s=size, color=color, label=label)\n",
    "\n",
    "        elif features == 'geo':\n",
    "            \n",
    "            if zoom is None:\n",
    "                zoom = (-180, 180, -60, 75)\n",
    "\n",
    "            m = Basemap(\n",
    "                projection='merc',\n",
    "                llcrnrlat=zoom[2],\n",
    "                urcrnrlat=zoom[3],\n",
    "                llcrnrlon=zoom[0],\n",
    "                urcrnrlon=zoom[1],\n",
    "                lat_ts=20,\n",
    "                resolution='c'\n",
    "            )\n",
    "            m.drawcoastlines()\n",
    "            m.fillcontinents(color='white', lake_color='white')\n",
    "            m.drawparallels(np.arange(-90.,91.,30.), labels=[True,False,False,False])\n",
    "            m.drawmeridians(np.arange(-180.,181.,60.), labels=[False,True,True,False])\n",
    "            m.drawmapboundary(fill_color='white')\n",
    "\n",
    "            \n",
    "            if color_families:\n",
    "                other = df[~df[color_families].any(axis=1)]\n",
    "                m.scatter(*m(other.longitude, other.latitude), 3, c='gray', marker='o', zorder=3, label='Other' if legend_families else None, alpha=alpha)\n",
    "                for family in color_families:\n",
    "                    family_df = df[df[family] == 1]\n",
    "                    m.scatter(*m(family_df.longitude, family_df.latitude), 10, marker='o', label=family if legend_families else None, zorder=3, alpha=alpha)\n",
    "                    # TODO: fix colors\n",
    "                    # TODO: select each language only once, e.g. Indo-European vs Slavic\n",
    "            else:\n",
    "                m.scatter(*m(df.longitude, df.latitude), 10, marker='o', color='gray', zorder=3, alpha=alpha)\n",
    "                \n",
    "            if evaluation is not None:\n",
    "                subset_df = df.loc[evaluation.languages]\n",
    "                plt.scatter(*m(subset_df['longitude'], subset_df['latitude']), s=evaluation.sizes, c=evaluation.colors, zorder=3)\n",
    "                \n",
    "                if evaluation.legend:\n",
    "                    for label, color, size in zip(evaluation.legend['labels'], evaluation.legend['colors'], evaluation.legend['sizes']):\n",
    "                        plt.scatter(None, None, s=size, color=color, label=label)                \n",
    "            \n",
    "        else:\n",
    "            raise AttributeError('Attribute `features` muse be either `uriel` or `geo`.')\n",
    "    \n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            \n",
    "    elif backend == 'bokeh':\n",
    "        ...\n",
    "\n",
    "class Evaluation:\n",
    "    \n",
    "    def __init__(self, languages, sizes, colors, legend):\n",
    "        self.languages = languages\n",
    "        self.sizes = sizes\n",
    "        self.colors = colors\n",
    "        self.legend = legend\n",
    "        \n",
    "    def visualize(self, *args, **kwargs):\n",
    "        visualize(*args, **kwargs, evaluation=self)\n",
    "    \n",
    "    @classmethod\n",
    "    def compare_two_methods(cls, languages, score_diff, method_names):\n",
    "        \n",
    "        colors = ['g' if s > 0 else 'r' for s in score_diff]\n",
    "        scores = [s if s > 0 else -s for s in score_diff]\n",
    "        mx, mn = max(scores), min(scores)\n",
    "        scores = [s - min(scores) for s in scores]  # normalization\n",
    "        scores = [s / max(scores) for s in scores]  # normalization\n",
    "        sizes = [s * 90 + 10 for s in scores]  # 20-100 scale\n",
    "        \n",
    "        method_a, method_b = method_names\n",
    "        legend = {\n",
    "            'labels': [\n",
    "                f'{method_a} wins by {mx}',\n",
    "                f'{method_a} wins by {(mx + mn) / 2}',\n",
    "                f'{method_a} wins by {mn}',\n",
    "                f'{method_b} wins by {mn}',\n",
    "                f'{method_b} wins by {(mx + mn) / 2}',\n",
    "                f'{method_b} wins by {mx}',\n",
    "            ],\n",
    "            'colors': ['g', 'g', 'g', 'r', 'r', 'r'],\n",
    "            'sizes': [100, 55, 10, 10, 55, 100],\n",
    "        }\n",
    "        \n",
    "        return Evaluation(\n",
    "            languages=languages,\n",
    "            sizes=sizes,\n",
    "            colors=colors,\n",
    "            legend=legend,\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def show_winner(cls, languages, winners):\n",
    "        methods = list(set(winners))\n",
    "        cm = matplotlib.cm.get_cmap('tab20').colors\n",
    "        cm = cm[::2] + cm[1::2]\n",
    "        \n",
    "        legend = {\n",
    "            'labels': methods,\n",
    "            'colors': cm[:len(methods)],\n",
    "            'sizes': [50 for _ in range(len(methods))],\n",
    "        }\n",
    "        \n",
    "        return Evaluation(\n",
    "            languages=languages,\n",
    "            sizes=50,\n",
    "            colors=[cm[methods.index(w)] for w in winners],\n",
    "            legend=legend,\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def show_languages(cls, languages, color='r'):\n",
    "        return Evaluation(\n",
    "            languages=languages,\n",
    "            sizes=50,\n",
    "            colors=color,\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def show_performance(cls, languages, scores, color='r'):  # scores should be scaled by user and with max being better\n",
    "        mn, mx = min(scores), max(scores)\n",
    "        scores = [s - min(scores) for s in scores]  # normalization\n",
    "        scores = [s / max(scores) for s in scores]  # normalization\n",
    "        sizes = [s * 90 + 10 for s in scores]  # 20-100 scale\n",
    "        \n",
    "        legend = {\n",
    "            'labels': [\n",
    "                f'{mn}',\n",
    "                f'{(mx + mn) / 2}',\n",
    "                f'{mx}',\n",
    "            ],\n",
    "            'colors': [color, color, color],\n",
    "            'sizes': [10, 55, 100],\n",
    "        }\n",
    "        \n",
    "        # TODO: legend\n",
    "        return Evaluation(\n",
    "            languages=languages,\n",
    "            sizes=sizes,\n",
    "            colors=color,\n",
    "            legend=legend,\n",
    "        )\n",
    "        \n",
    "Evaluation.show_performance(['slk', 'ces', 'hbs', 'rus', 'eng'], [75, 80, 79, 65, 90]).\\\n",
    "visualize('matplotlib', 'uriel', alpha=0.1, color_families=True, legend_families=False)#, zoom=[0,10,-5,5])\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.plot\n",
    "import bokeh\n",
    "\n",
    "hover_data = pd.DataFrame({\n",
    "    'family': df['family_str'],\n",
    "    'iso': df.index,\n",
    "    'name': df['name'],\n",
    "})\n",
    "hover_data.index = range(7970)\n",
    "\n",
    "p = umap.plot.interactive(\n",
    "    umap_object,\n",
    "    hover_data=hover_data,\n",
    "    interactive_text_search=True,\n",
    "    point_size=4,\n",
    ")\n",
    "bokeh.plotting.output_notebook() \n",
    "bokeh.plotting.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from types import FunctionType\n",
    "from utils import language_iso\n",
    "\n",
    "@language_iso\n",
    "def rahimi_ner():\n",
    "    languages = [line.split()[0] for line in open('./papers/rahimi_ner.txt')]\n",
    "    scores = np.vstack([\n",
    "        [float(v) for v in line.split()[2:]]\n",
    "        for line\n",
    "        in open('./papers/rahimi_ner.txt')\n",
    "    ])\n",
    "    return languages, scores\n",
    "\n",
    "@language_iso\n",
    "def heinzerling_ner():\n",
    "    languages = [line.split()[0] for line in open('./papers/heinzerling_ner.txt')]\n",
    "    scores = np.vstack([\n",
    "        [float(v) for v in line.split()[1:]]\n",
    "        for line\n",
    "        in open('./papers/heinzerling_ner.txt')\n",
    "    ])\n",
    "    return languages, scores\n",
    "\n",
    "@language_iso\n",
    "def heinzerling_pos():\n",
    "    languages = [line.split()[0] for line in open('./papers/heinzerling_pos.txt')]\n",
    "    scores = np.vstack([\n",
    "        [float(v) for v in line.split()[1:]]\n",
    "        for line\n",
    "        in open('./papers/heinzerling_pos.txt')\n",
    "    ])\n",
    "    return languages, scores\n",
    "\n",
    "@language_iso\n",
    "def heinzerling_pos_low():\n",
    "    languages = [line.split()[0] for line in open('./papers/heinzerling_pos_low.txt')]\n",
    "    scores = np.vstack([\n",
    "        [float(v) for v in line.split()[1:]]\n",
    "        for line\n",
    "        in open('./papers/heinzerling_pos_low.txt')\n",
    "    ])\n",
    "    r_languages, r_scores = heinzerling_pos()\n",
    "    languages += r_languages\n",
    "    scores = np.vstack([scores, r_scores[:, [1,2,4,10]]])\n",
    "    return languages, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [line.split()[0] for line in open('./papers/heinzerling_ner.txt')]\n",
    "languages = [LETTER_CODES.get(l, l) for l in languages]\n",
    "languages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
